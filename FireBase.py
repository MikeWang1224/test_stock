# -*- coding: utf-8 -*-
"""
FireBase_Attention_LSTM_Direction.py
- Attention-LSTM
- Multi-task: Return path + Direction
- âœ… å°è³‡æ–™å‹å–„ç‰ˆï¼šæ›´ç©©ã€æ›´ä¸å®¹æ˜“äº‚å™´
  1) LOOKBACK=40, STEPS=5
  2) LSTM + Attention poolingï¼ˆåƒæ•¸æ¯” Transformer æ›´é©åˆå°è³‡æ–™ï¼‰ 
  3) âœ… Return head åŠ  tanh é™å¹…ï¼ˆé¿å…é æ¸¬çˆ†ç‚¸ï¼‰
  4) âœ… Volume åš log1pï¼ˆå°è³‡æ–™æ›´ç©©ï¼‰
- åœ–è¡¨è¼¸å‡ºå®Œå…¨ä¸è®Šï¼ˆä¿ç•™ Today æ¨™è¨˜ï¼‰

âœ… æ”¹1ï¼šä¿®æ­£ scaler fit / split åº§æ¨™ç³»ï¼Œé¿å…è³‡æ–™æ´©æ¼ï¼ˆleakageï¼‰
  - create_sequences å›å‚³æ¯å€‹æ¨£æœ¬å°æ‡‰çš„æ—¥æœŸ idx
  - split ç”¨æ¨£æœ¬æ•¸åˆ‡ï¼Œscaler.fit åªç”¨ train å€é–“çš„ df ç‰¹å¾µ

âœ… æ–°å¢ï¼šåŒæ™‚è¼¸å‡º PNG + CSV
  - results/YYYY-MM-DD_pred.png
  - results/YYYY-MM-DD_forecast.csv
  - results/YYYY-MM-DD_backtest.png
  - results/YYYY-MM-DD_backtest.csv
"""

import os, json
import numpy as np
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt
from pandas.tseries.offsets import BDay

from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, LSTM, Dense, Dropout,
    Softmax, Lambda
)
from tensorflow.keras.callbacks import EarlyStopping

from datetime import datetime
from zoneinfo import ZoneInfo

now_tw = datetime.now(ZoneInfo("Asia/Taipei"))
# Firebase
import firebase_admin
from firebase_admin import credentials, firestore

# ================= Firebase åˆå§‹åŒ– =================
key_dict = json.loads(os.environ.get("FIREBASE", "{}"))
db = None

if key_dict:
    cred = credentials.Certificate(key_dict)
    try:
        firebase_admin.get_app()
    except Exception:
        firebase_admin.initialize_app(cred)
    db = firestore.client()

# ================= Firestore è®€å– =================
def load_df_from_firestore(ticker, collection="NEW_stock_data_liteon", days=500):
    rows = []
    if db:
        for doc in db.collection(collection).stream():
            p = doc.to_dict().get(ticker)
            if p:
                rows.append({"date": doc.id, **p})

    df = pd.DataFrame(rows)
    if df.empty:
        raise ValueError("âš ï¸ Firestore ç„¡è³‡æ–™")

    df["date"] = pd.to_datetime(df["date"])
    df = df.sort_values("date").tail(days).set_index("date")
    return df

# ================= å‡æ—¥è£œä»Šå¤© =================
def ensure_today_row(df):
    today = pd.Timestamp(datetime.now().date())
    last_date = df.index.max()
    if last_date < today:
        df.loc[today] = df.loc[last_date]
        print(f"âš ï¸ ä»Šæ—¥ç„¡è³‡æ–™ï¼Œä½¿ç”¨ {last_date.date()} è£œä»Šæ—¥")
    return df.sort_index()

# ================= Feature Engineering =================
def add_features(df: pd.DataFrame) -> pd.DataFrame:
    # âœ… Volume å°ºåº¦ç©©å®šï¼ˆéå¸¸å»ºè­°ï¼‰
    if "Volume" in df.columns:
        df["Volume"] = np.log1p(df["Volume"].astype(float))

    # åœ–è¡¨ç”¨å‡ç·šï¼ˆä¿æŒä¸è®Šï¼‰
    df["SMA5"] = df["Close"].rolling(5).mean()
    df["SMA10"] = df["Close"].rolling(10).mean()
    return df

# ================= Sequenceï¼ˆé¿å…éŒ¯ä½ï¼Œä¸”ä¸äº‚åˆ‡ dfï¼‰ =================
def create_sequences(df, features, steps=5, window=40):
    """
    X: t-window ~ t-1
    y_ret: t ~ t+steps-1 çš„ log return
    y_dir: æœªä¾† steps å¤©ç´¯ç©æ–¹å‘
    idx: æ¯å€‹æ¨£æœ¬å°æ‡‰çš„ã€Œt ç•¶å¤©æ—¥æœŸã€ï¼ˆç”¨ä¾†é¿å… scaler/split åº§æ¨™ç³»éŒ¯ä½ï¼‰
    """
    X, y_ret, y_dir, idx = [], [], [], []

    close = df["Close"].astype(float)
    logret = np.log(close).diff()
    feat = df[features].values

    for i in range(window, len(df) - steps):
        x_seq = feat[i - window:i]
        future_ret = logret.iloc[i:i + steps].values
        if np.any(np.isnan(future_ret)) or np.any(np.isnan(x_seq)):
            continue
        X.append(x_seq)
        y_ret.append(future_ret)
        y_dir.append(1.0 if future_ret.sum() > 0 else 0.0)
        idx.append(df.index[i])  # âœ… é€™å€‹æ¨£æœ¬å°æ‡‰çš„ t æ—¥æœŸ

    return np.array(X), np.array(y_ret), np.array(y_dir), np.array(idx)

# ================= Attention-LSTMï¼ˆâœ… return é™å¹…ï¼‰ =================
def build_attention_lstm(input_shape, steps, max_daily_logret=0.06):
    """
    max_daily_logretï¼šé™åˆ¶å–®æ—¥ log-return æœ€å¤§å¹…åº¦ï¼Œé¿å…é€£ä¹˜åƒ¹æ ¼çˆ†ç‚¸
    å¸¸è¦‹ç¯„åœï¼š0.04~0.08
    """
    inp = Input(shape=input_shape)

    x = LSTM(64, return_sequences=True)(inp)
    x = Dropout(0.2)(x)

    score = Dense(1, name="attn_score")(x)                 # (batch, time, 1)
    weights = Softmax(axis=1, name="attn_weights")(score)  # softmax over time
    context = Lambda(lambda t: tf.reduce_sum(t[0] * t[1], axis=1),
                     name="attn_context")([x, weights])    # (batch, hidden)

    # âœ… return headï¼štanh é™å¹…ï¼ˆçµæ§‹æ€§ä¿è­‰ä¸æœƒçˆ†ï¼‰
    raw = Dense(steps, activation="tanh")(context)          # [-1, 1]
    out_ret = Lambda(lambda t: t * max_daily_logret, name="return")(raw)

    out_dir = Dense(1, activation="sigmoid", name="direction")(context)

    model = Model(inp, [out_ret, out_dir])
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=7e-4),
        loss={
            "return": tf.keras.losses.Huber(),
            "direction": "binary_crossentropy"
        },
        loss_weights={
            "return": 1.0,
            "direction": 0.4
        },
        metrics={
            "direction": [tf.keras.metrics.BinaryAccuracy(name="acc"),
                          tf.keras.metrics.AUC(name="auc")]
        }
    )
    return model

# ================= åŸé æ¸¬åœ–ï¼ˆå®Œå…¨ä¸å‹•ï¼šæ–°å¢ Today æ¨™è¨˜ï¼‰ =================
def plot_and_save(df_hist, future_df):
    hist = df_hist.tail(10)
    hist_dates = hist.index.strftime("%m-%d").tolist()
    future_dates = future_df["date"].dt.strftime("%m-%d").tolist()

    all_dates = hist_dates + future_dates
    x_hist = np.arange(len(hist_dates))
    x_future = np.arange(len(hist_dates), len(all_dates))

    plt.figure(figsize=(18,8))
    ax = plt.gca()

    ax.plot(x_hist, hist["Close"], label="Close")
    ax.plot(x_hist, hist["SMA5"], label="SMA5")
    ax.plot(x_hist, hist["SMA10"], label="SMA10")

    # âœ… Today é»èˆ‡æ–‡å­—ï¼ˆhist æœ€å¾Œä¸€å€‹é»ï¼‰
    today_x = x_hist[-1]
    today_y = float(hist["Close"].iloc[-1])
    ax.scatter([today_x], [today_y], marker="*", s=160, label="Today Close")
    ax.text(today_x, today_y + 0.3, f"Today {today_y:.2f}", 
            fontsize=17, ha="center")

    ax.plot(
        np.concatenate([[x_hist[-1]], x_future]),
        [hist["Close"].iloc[-1]] + future_df["Pred_Close"].tolist(),
        "r:o", label="Pred Close"
    )

    for i, price in enumerate(future_df["Pred_Close"]):
        ax.text(x_future[i], price + 0.3, f"{price:.2f}",
                color="red", fontsize=15, ha="center")

    ax.plot(
        np.concatenate([[x_hist[-1]], x_future]),
        [hist["SMA5"].iloc[-1]] + future_df["Pred_MA5"].tolist(),
        "g--o", label="Pred MA5"
    )

    ax.plot(
        np.concatenate([[x_hist[-1]], x_future]),
        [hist["SMA10"].iloc[-1]] + future_df["Pred_MA10"].tolist(),
        "b--o", label="Pred MA10"
    )

    ax.set_xticks(np.arange(len(all_dates)))
    ax.set_xticklabels(all_dates, rotation=45, ha="right", fontsize=15)
    ax.legend()
    ax.set_title("2301.TW Attention-LSTM é æ¸¬")

    os.makedirs("results", exist_ok=True)
    plt.savefig(f"results/{datetime.now():%Y-%m-%d}_pred.png",
                dpi=300, bbox_inches="tight")
    plt.close()
# ================= å›æ¸¬æ±ºç­–åˆ†å²”åœ–ï¼ˆPNG + CSVï¼‰ =================
def plot_backtest_error(df):
    """
    æ±ºç­–å¼å›æ¸¬åœ–ï¼ˆDecision-based Backtestï¼‰

    ç‰¹æ€§ï¼š
    - è‡ªå‹•æ’é™¤ä»Šå¤©çš„ forecast
    - ä½¿ç”¨æœ€è¿‘ä¸€ç­†æ­·å² forecast
    - ä¸å— ensure_today_row() å‡è³‡æ–™å½±éŸ¿
    - ä¸æ€•é€±æœ« / åœå¸‚
    - åœ–ä¸­åŠ å…¥ run timestampï¼Œç¢ºä¿ Git æ¯æ¬¡éƒ½æœƒæ›´æ–° PNG
    """

    today = pd.Timestamp(datetime.now().date())

    # ================= æ‰¾æœ€è¿‘ä¸€æ¬¡ï¼ˆæ’é™¤ä»Šå¤©ï¼‰çš„ forecast =================
    if not os.path.exists("results"):
        print("âš ï¸ ç„¡ results è³‡æ–™å¤¾ï¼Œç•¥éå›æ¸¬")
        return

    forecast_files = []
    for f in os.listdir("results"):
        if not f.endswith("_forecast.csv"):
            continue
        try:
            d = pd.to_datetime(f.split("_")[0])
        except Exception:
            continue

        if d < today:  # æ˜ç¢ºæ’é™¤ä»Šå¤©
            forecast_files.append((d, f))

    if not forecast_files:
        print("âš ï¸ æ‰¾ä¸åˆ°å¯ç”¨çš„æ­·å² forecastï¼ˆå·²æ’é™¤ä»Šå¤©ï¼‰")
        return

    forecast_files.sort(key=lambda x: x[0], reverse=True)
    forecast_date, forecast_name = forecast_files[0]
    forecast_csv = os.path.join("results", forecast_name)

    print(f"ğŸ“„ Backtest ä½¿ç”¨ forecastï¼š{forecast_name}")

    future_df = pd.read_csv(forecast_csv, parse_dates=["date"])

    # ================= æ±ºç­–æ—¥ tï¼ˆæœ€å¾Œä¸€å€‹çœŸå¯¦äº¤æ˜“æ—¥ï¼‰ =================
    valid_days = df.index[df.index < today]

    if len(valid_days) < 2:
        print("âš ï¸ ç„¡è¶³å¤ æ­·å²äº¤æ˜“æ—¥ï¼Œç•¥éå›æ¸¬")
        return

    t = valid_days[-1]
    t1 = t + BDay(1)

    # ================= åƒ¹æ ¼ =================
    close_t = float(df.loc[t, "Close"])
    pred_t1 = float(future_df.loc[0, "Pred_Close"])

    if t1 in df.index:
        actual_t1 = float(df.loc[t1, "Close"])
    else:
        actual_t1 = float(df["Close"].iloc[-1])

    # ================= è¶¨å‹¢èƒŒæ™¯ï¼ˆä¸‰å¤©ï¼‰ =================
    trend = df.loc[:t].tail(4)
    x_trend = np.arange(len(trend))
    x_t = x_trend[-1]

       # ================= ç•«åœ– =================
    plt.figure(figsize=(14, 6))
    ax = plt.gca()
    
    # æœ€è¿‘æ”¶ç›¤è¶¨å‹¢
    ax.plot(
        x_trend,
        trend["Close"],
        "k-o",
        label="Recent Close"
    )
    
    # Pred ç·š
    ax.plot(
        [x_t, x_t + 1],
        [close_t, pred_t1],
        "r--o",
        linewidth=2.5,
        label="Pred (t â†’ t+1)"
    )
    
    # Actual ç·š
    ax.plot(
        [x_t, x_t + 1],
        [close_t, actual_t1],
        "g-o",
        linewidth=2.5,
        label="Actual (t â†’ t+1)"
    )
    
    # ================= æ•¸å€¼æ¨™è¨»ï¼ˆå…¨éƒ¨çµ±ä¸€åœ¨é»å³é‚Šï¼‰ =================
    dx = 0.08   
    price_offset = max(0.2, close_t * 0.002)# æˆ–ä¾è‚¡åƒ¹èª¿æ•´ï¼Œä¾‹å¦‚ 0.2 ~ 0.5

    ax.text( 
        x_t,
        close_t + price_offset, 
        f"{close_t:.2f}", 
        ha="center", 
        va="bottom",   
        fontsize=18, 
        color="black" 
    )
    # Pred t+1
    ax.text(
        x_t + 1 + dx,
        pred_t1,
        f"Pred {pred_t1:.2f}",
        ha="left",
        va="center",
        fontsize=16,
        color="red"
    )
    
    # Actual t+1
    ax.text(
        x_t + 1 + dx,
        actual_t1,
        f"Actual {actual_t1:.2f}",
        ha="left",
        va="center",
        fontsize=16,
        color="green"
    )
    
    # ================= X è»¸ =================
    labels = trend.index.strftime("%m-%d").tolist()
    labels.append(t1.strftime("%m-%d"))
    ax.set_xticks(np.arange(len(labels)))
    ax.set_xticklabels(labels)
    
    ax.set_title("2301.TW Decision Backtest (t â†’ t+1)")
    ax.legend()
    ax.grid(alpha=0.3)
    
    # ================= Run timestamp =================
    ax.text(
        0.01, 0.01,
        f"Generated at {now_tw:%Y-%m-%d %H:%M:%S} (TW)",
        transform=ax.transAxes,
        fontsize=8,
        alpha=0.4,
        ha="left",
        va="bottom"
    )



    # ================= å„²å­˜ =================
    os.makedirs("results", exist_ok=True)
    print(f"ğŸ–¼ï¸ å„²å­˜ backtest åœ–ï¼š{today:%Y-%m-%d}_backtest.png")

    plt.savefig(
        f"results/{today:%Y-%m-%d}_backtest.png",
        dpi=300,
        bbox_inches="tight"
    )
    plt.close()

    # ================= CSVï¼ˆå–®ç­†æ±ºç­–ï¼‰ =================
    bt = pd.DataFrame([{
        "forecast_date": forecast_date.date(),
        "decision_day": t.date(),
        "close_t": close_t,
        "pred_t1": pred_t1,
        "actual_t1": actual_t1,
        "direction_pred": int(np.sign(pred_t1 - close_t)),
        "direction_actual": int(np.sign(actual_t1 - close_t))
    }])

    bt.to_csv(
        f"results/{today:%Y-%m-%d}_backtest.csv",
        index=False,
        encoding="utf-8-sig"
    )

    # ================= CSVï¼ˆå–®ç­†æ±ºç­–ï¼‰ =================
    bt = pd.DataFrame([{
        "forecast_date": forecast_date.date(),
        "decision_day": t.date(),
        "close_t": close_t,
        "pred_t1": pred_t1,
        "actual_t1": actual_t1,
        "direction_pred": int(np.sign(pred_t1 - close_t)),
        "direction_actual": int(np.sign(actual_t1 - close_t))
    }])

    bt.to_csv(
        f"results/{today:%Y-%m-%d}_backtest.csv",
        index=False,
        encoding="utf-8-sig"
    )

# ================= Main =================
if __name__ == "__main__":
    TICKER = "2301.TW"
    LOOKBACK = 40
    STEPS = 5

    df = load_df_from_firestore(TICKER, days=500)
    df = ensure_today_row(df)
    df = add_features(df)

    FEATURES = ["Close", "Volume", "RSI", "MACD", "K", "D", "ATR_14"]

    df = df.dropna()

    X, y_ret, y_dir, idx = create_sequences(df, FEATURES, steps=STEPS, window=LOOKBACK)
    print(f"df rows: {len(df)} | X samples: {len(X)}")

    if len(X) < 40:
        raise ValueError("âš ï¸ å¯ç”¨åºåˆ—å¤ªå°‘ï¼ˆ<40ï¼‰ã€‚å»ºè­°ï¼šé™ä½ LOOKBACK/STEPS æˆ–æª¢æŸ¥è³‡æ–™æ˜¯å¦ç¼ºæ¬„ä½/éå¤š NaNã€‚")

    split = int(len(X) * 0.85)

    X_tr, X_te = X[:split], X[split:]
    y_ret_tr, y_ret_te = y_ret[:split], y_ret[split:]
    y_dir_tr, y_dir_te = y_dir[:split], y_dir[split:]
    idx_tr, idx_te = idx[:split], idx[split:]

    # âœ… scaler.fit åƒ…ç”¨ train å€é–“ï¼ˆç”¨ idx_tr çš„æœ€å¾Œæ—¥æœŸç•Œå®šï¼‰
    train_end_date = pd.Timestamp(idx_tr[-1])
    df_for_scaler = df.loc[:train_end_date, FEATURES].copy()

    if len(df_for_scaler) < LOOKBACK + 5:
        raise ValueError("âš ï¸ train å€é–“å¤ªçŸ­ï¼Œç„¡æ³•ç©©å®š fit scalerã€‚è«‹ç¢ºèªè³‡æ–™é‡æˆ–èª¿æ•´ LOOKBACKã€‚")

    sx = MinMaxScaler()
    sx.fit(df_for_scaler.values)

    def scale_X(Xb):
        n, t, f = Xb.shape
        return sx.transform(Xb.reshape(-1, f)).reshape(n, t, f)

    X_tr_s = scale_X(X_tr)
    X_te_s = scale_X(X_te)

    model = build_attention_lstm(
        (LOOKBACK, len(FEATURES)),
        STEPS,
        max_daily_logret=0.06
    )

    model.fit(
        X_tr_s,
        {"return": y_ret_tr, "direction": y_dir_tr},
        epochs=80,
        batch_size=16,
        verbose=2,
        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)]
    )

    pred_ret, pred_dir = model.predict(X_te_s, verbose=0)
    raw_returns = pred_ret[-1]  # âœ… å·²è¢«çµæ§‹æ€§é™å¹…

    print(f"ğŸ“ˆ é æ¸¬æ–¹å‘æ©Ÿç‡ï¼ˆçœ‹æ¼²ï¼‰: {pred_dir[-1][0]:.2%}")

    asof_date = df.index.max()
    last_close = float(df.loc[asof_date, "Close"])

    prices = []
    price = last_close
    for r in raw_returns:
        price *= np.exp(r)
        prices.append(price)

    seq = df.loc[:asof_date, "Close"].iloc[-10:].tolist()
    future = []
    for p in prices:
        seq.append(p)
        future.append({
            "Pred_Close": float(p),
            "Pred_MA5": float(np.mean(seq[-5:])),
            "Pred_MA10": float(np.mean(seq[-10:]))
        })

    future_df = pd.DataFrame(future)
    future_df["date"] = pd.bdate_range(
        start=df.index.max() + BDay(1),
        periods=STEPS
    )

    # âœ… é æ¸¬æ•¸å€¼è¼¸å‡º CSVï¼ˆéš”å¤©è¦ç–Šä»Šæ—¥å¯¦éš›ç”¨é€™ä»½ï¼‰
    os.makedirs("results", exist_ok=True)
    future_df.to_csv(f"results/{datetime.now():%Y-%m-%d}_forecast.csv",
                     index=False, encoding="utf-8-sig")

    plot_and_save(df, future_df)
    plot_backtest_error(df)

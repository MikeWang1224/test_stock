# -*- coding: utf-8 -*-
"""
æ”¹è‰¯ç‰ˆï¼šå…‰å¯¶ç§‘ï¼ˆ2301.TWï¼‰å¤šæ­¥ LSTM -> é æ¸¬æœªä¾† 10 å€‹äº¤æ˜“æ—¥ Closeï¼Œå†è¨ˆç®— MA5/MA10
é‡é»æ”¹é€²ï¼š
 - é æ¸¬ç›®æ¨™æ”¹ç‚ºæœªä¾† 10 æ—¥ Closeï¼ˆmulti-stepï¼‰
 - æ–°å¢æŠ€è¡“ç‰¹å¾µï¼ˆreturns, ATR, Bollinger, OBV, SMA diffsï¼‰
 - æ™‚åº train/test splitï¼ˆé¿å…è³‡æ–™æ´©æ¼ï¼‰
 - EarlyStopping / ModelCheckpoint / æ›´å¥½çš„ scaler ä½¿ç”¨
 - è©•ä¼°ä½¿ç”¨ MAE / RMSEï¼Œä¸¦ä»¥é æ¸¬ closes è¨ˆç®— Pred MA5/MA10 åšæœ€çµ‚æ¯”å°
"""
import os, json
import firebase_admin
from firebase_admin import credentials, firestore
import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from pandas.tseries.offsets import BDay
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import math

# ---------------- Firebase åˆå§‹åŒ– ----------------
key_dict = json.loads(os.environ.get("FIREBASE", "{}"))
if key_dict:
    cred = credentials.Certificate(key_dict)
    try:
        firebase_admin.get_app()
    except:
        firebase_admin.initialize_app(cred)
    db = firestore.client()
else:
    db = None
    print("âš ï¸ FIREBASE env æœªè¨­å®š â€” æœƒç•¥éä¸Šå‚³æ­¥é©Ÿ")

# ---------------- ç‰¹å¾µå·¥ç¨‹å‡½å¼ ----------------
def add_technical_features(df):
    df = df.copy()
    # SMA
    df['SMA_5'] = df['Close'].rolling(5).mean()
    df['SMA_10'] = df['Close'].rolling(10).mean()
    df['SMA_20'] = df['Close'].rolling(20).mean()

    # returns & log returns
    df['RET_1'] = df['Close'].pct_change().fillna(0)
    df['LOG_RET_1'] = np.log(df['Close'] / df['Close'].shift(1)).fillna(0)

    # SMA diffs
    df['Close_minus_SMA5'] = df['Close'] - df['SMA_5']
    df['SMA5_minus_SMA10'] = df['SMA_5'] - df['SMA_10']

    # ATR (Average True Range)
    high_low = df['High'] - df['Low']
    high_close = (df['High'] - df['Close'].shift(1)).abs()
    low_close = (df['Low'] - df['Close'].shift(1)).abs()
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['ATR_14'] = tr.rolling(14).mean()

    # Bollinger Bands
    df['BB_mid'] = df['Close'].rolling(20).mean()
    df['BB_std'] = df['Close'].rolling(20).std()
    df['BB_upper'] = df['BB_mid'] + 2 * df['BB_std']
    df['BB_lower'] = df['BB_mid'] - 2 * df['BB_std']
    df['BB_width'] = (df['BB_upper'] - df['BB_lower']) / df['BB_mid']

    # OBV (On Balance Volume)
    obv = [0]
    for i in range(1, len(df)):
        if df['Close'].iloc[i] > df['Close'].iloc[i-1]:
            obv.append(obv[-1] + df['Volume'].iloc[i])
        elif df['Close'].iloc[i] < df['Close'].iloc[i-1]:
            obv.append(obv[-1] - df['Volume'].iloc[i])
        else:
            obv.append(obv[-1])
    df['OBV'] = obv
    df['OBV_SMA_20'] = df['OBV'].rolling(20).mean()

    # Volume moving average
    df['Vol_SMA_5'] = df['Volume'].rolling(5).mean()
    df['Vol_SMA_20'] = df['Volume'].rolling(20).mean()

    # fill / drop
    df = df.dropna()
    return df

# ---------------- å–å¾—è³‡æ–™ä¸¦è¨ˆæŒ‡æ¨™ ----------------
def fetch_and_prepare(ticker="2301.TW", period="12mo"):
    stock = yf.Ticker(ticker)
    df = stock.history(period=period)
    df = add_technical_features(df)
    return df

# ---------------- æ›´æ–°ä»Šå¤© Close å¾ Firestoreï¼ˆè‹¥æœ‰ï¼‰ ----------------
def update_today_from_firestore(df):
    if db is None:
        return df
    today_str = datetime.now().strftime("%Y-%m-%d")
    doc_ref = db.collection("NEW_stock_data_liteon").document(today_str)
    doc = doc_ref.get()
    if doc.exists:
        data = doc.to_dict().get("2301.TW", {})
        if "Close" in data:
            try:
                df.loc[pd.Timestamp(today_str), 'Close'] = float(data["Close"])
            except Exception:
                pass
    df = df.dropna()
    return df

# ---------------- å„²å­˜åˆ° Firestoreï¼ˆé¸ç”¨ï¼‰ ----------------
def save_to_firestore(df):
    if db is None:
        print("è·³é Firestore å¯«å…¥ï¼ˆæœªè¨­å®šï¼‰")
        return
    selected = ['Close', 'MACD', 'RSI', 'K', 'D', 'Volume'] if 'MACD' in df.columns else ['Close', 'Volume']
    collection = "NEW_stock_data_liteon"
    batch = db.batch()
    count = 0
    for idx, row in df.iterrows():
        date_str = idx.strftime("%Y-%m-%d")
        data = {col: float(row[col]) for col in selected if col in row and not pd.isna(row[col])}
        doc_ref = db.collection(collection).document(date_str)
        batch.set(doc_ref, {"2301.TW": data})
        count += 1
        if count >= 300:
            batch.commit()
            batch = db.batch()
            count = 0
    batch.commit()
    print("ğŸ”¥ Firestore å¯«å…¥å®Œæˆ")

# ---------------- å»ºè³‡æ–™é›†ï¼ˆç”¨ sliding windowï¼‰ ----------------
def create_sequences(df, features, target_steps=10, window=60):
    """
    X: sequences of 'window' days of feature vectors
    y: next target_steps of Close values
    """
    X, y = [], []
    closes = df['Close'].values
    data = df[features].values
    for i in range(window, len(df) - target_steps + 1):
        X.append(data[i-window:i])
        y.append(closes[i:i+target_steps])  # next target_steps closes
    X = np.array(X)
    y = np.array(y)
    return X, y

# ---------------- å»ºæ¨¡å‹ï¼ˆmulti-step LSTMï¼‰ ----------------
def build_lstm_multi_step(input_shape, output_steps=10):
    model = Sequential()
    model.add(LSTM(128, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.2))
    model.add(LSTM(64))
    model.add(Dropout(0.2))
    model.add(Dense(output_steps))  # output future closes for next N days
    model.compile(optimizer='adam', loss='mae')  # MAE æå¤±
    return model

# ---------------- æ™‚åº train/test splitï¼ˆæœ€ç°¡å–®çš„ time-based splitï¼‰ ----------------
def time_series_split(X, y, test_ratio=0.15):
    n = len(X)
    test_n = int(n * test_ratio)
    split_idx = n - test_n
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    return X_train, X_test, y_train, y_test

# ---------------- å¾é æ¸¬ closes è¨ˆç®— MA5 / MA10ï¼ˆä»¥æ¨¡å‹è¼¸å‡ºç‚ºåŸºç¤ï¼‰ ----------------
def compute_pred_ma_from_pred_closes(last_known_closes, pred_closes):
    """
    last_known_closes: array of close values up to today (éœ€åŒ…å«è¶³å¤ é•·åº¦è¨ˆç®— MA)
    pred_closes: array (n_steps,) æ¨¡å‹é æ¸¬çš„æœªä¾† closesï¼ˆæŒ‰æ™‚é–“é †åºï¼‰
    ä¾åºæŠŠé æ¸¬ append åˆ° last_known_closesï¼Œå†è¨ˆç®—æ¯å€‹æœªä¾†æ—¥çš„ MA5/M A10
    å›å‚³ dataframe: date, Pred_Close, Pred_MA5, Pred_MA10
    """
    closes_seq = list(last_known_closes)[:]  # copy
    results = []
    for pc in pred_closes:
        closes_seq.append(pc)
        # compute MA5 & MA10 using last available values
        ma5 = np.mean(closes_seq[-5:]) if len(closes_seq) >= 5 else np.mean(closes_seq)
        ma10 = np.mean(closes_seq[-10:]) if len(closes_seq) >= 10 else np.mean(closes_seq)
        results.append((pc, ma5, ma10))
    return results

# ---------------- ç•«åœ–å‡½å¼ï¼ˆåªé¡¯ç¤ºäº¤æ˜“æ—¥ï¼Œx è»¸ç”¨é€±åˆ»åº¦ï¼‰ ----------------
def plot_all(df_real, df_future, hist_days=60):
    df_real = df_real.copy()
    df_real['date'] = pd.to_datetime(df_real.index).tz_localize(None)

    # å–æœ€è¿‘ hist_days å€‹ã€Œäº¤æ˜“æ—¥ã€
    df_plot_real = df_real.tail(hist_days)

    # df_future å·²ç‚ºå•†æ¥­æ—¥ï¼ˆä¸‹æ–¹ main ç”¢ç”Ÿï¼‰ï¼Œä½†ä»è½‰æˆ datetime
    df_future = df_future.copy()
    df_future['date'] = pd.to_datetime(df_future['date'])

    plt.figure(figsize=(16,8))

    # ç•«æ­·å²ç·šï¼ˆäº¤æ˜“æ—¥è‡ªç„¶é€£æ¥ï¼‰
    plt.plot(df_plot_real['date'], df_plot_real['Close'], label="Close")
    if 'SMA_5' in df_plot_real.columns:
        plt.plot(df_plot_real['date'], df_plot_real['SMA_5'], label="SMA5")
    if 'SMA_10' in df_plot_real.columns:
        plt.plot(df_plot_real['date'], df_plot_real['SMA_10'], label="SMA10")

    # ç•«é æ¸¬ç·šï¼ˆä½¿ç”¨å•†æ¥­æ—¥æ—¥æœŸï¼‰
    plt.plot(df_future['date'], df_future['Pred_Close'], ':', label='Pred Close')
    plt.plot(df_future['date'], df_future['Pred_MA5'], '--', label="Pred MA5")
    plt.plot(df_future['date'], df_future['Pred_MA10'], '--', label="Pred MA10")

    # x è»¸æ ¼å¼ï¼šæ¯é€±ä¸€å€‹åˆ»åº¦ï¼ˆé¿å…éå¯†ï¼‰
    plt.gca().xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO, interval=1))
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    plt.gcf().autofmt_xdate(rotation=45)

    plt.legend()
    plt.title("2301.TW æ­·å² + é æ¸¬ï¼ˆåƒ…äº¤æ˜“æ—¥ï¼Œç·šæ¢å®Œæ•´æ¥çºŒï¼‰")
    plt.xlabel("Date")
    plt.ylabel("Price")

    results_dir = "results"
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)
    today_str = datetime.now().strftime("%Y-%m-%d")
    file_path = f"{results_dir}/{today_str}_future.png"
    plt.savefig(file_path, dpi=300, bbox_inches='tight')
    plt.close()
    print("ğŸ“Œ åœ–ç‰‡å·²å„²å­˜ï¼š", file_path)


# ---------------- ä¸»æµç¨‹ ----------------
if __name__ == "__main__":
    # åƒæ•¸
    TICKER = "2301.TW"
    LOOKBACK = 60            # window size
    PRED_STEPS = 10          # è¦é æ¸¬æœªä¾† 10 æ—¥ Close (äº¤æ˜“æ—¥)
    PERIOD = "18mo"          # ç”¨æ›´å¤šæ­·å²èƒ½å¹«åŠ©è¨“ç·´ï¼ˆå¯èª¿ï¼‰
    TEST_RATIO = 0.15

    # æŠ“è³‡æ–™ + ç‰¹å¾µ
    df = fetch_and_prepare(ticker=TICKER, period=PERIOD)
    df = update_today_from_firestore(df)
    # å¯é¸ï¼šsave_to_firestore(df)

    # éœ€è¦çš„ç‰¹å¾µæ¬„ä½ (å¯å†æ“´å……)
    features = ['Close', 'Volume', 'RET_1', 'LOG_RET_1', 'Close_minus_SMA5',
                'SMA5_minus_SMA10', 'ATR_14', 'BB_width', 'OBV', 'OBV_SMA_20',
                'Vol_SMA_5']

    df_features = df[features].copy()
    df_features = df_features.dropna()

    # create sequences
    X, y = create_sequences(df_features, features, target_steps=PRED_STEPS, window=LOOKBACK)
    print("X shape:", X.shape, "y shape:", y.shape)

    # train/test split (time-based)
    X_train, X_test, y_train, y_test = time_series_split(X, y, test_ratio=TEST_RATIO)
    print("Train:", X_train.shape, "Test:", X_test.shape)

    # scaler: flatten time dimension for scaler fitting
    nsamples, tw, nfeatures = X_train.shape
    X_train_2d = X_train.reshape((nsamples*tw, nfeatures))
    scaler_x = MinMaxScaler()
    scaler_x.fit(X_train_2d)

    def scale_X(X_raw):
        s = X_raw.reshape((-1, X_raw.shape[-1]))
        s = scaler_x.transform(s)
        return s.reshape((X_raw.shape[0], X_raw.shape[1], X_raw.shape[2]))

    X_train_s = scale_X(X_train)
    X_test_s = scale_X(X_test)

    # y scaler: scale closes (é€ step)
    scaler_y = MinMaxScaler()
    y_train_2d = y_train  # shape (n_samples, PRED_STEPS)
    scaler_y.fit(y_train_2d)  # treat multi-output scaling
    y_train_s = scaler_y.transform(y_train_2d)
    y_test_s = scaler_y.transform(y_test)

    # build model
    model = build_lstm_multi_step(input_shape=(LOOKBACK, nfeatures), output_steps=PRED_STEPS)
    model.summary()

    # callbacks
    model_dir = "models"
    os.makedirs(model_dir, exist_ok=True)
    ckpt_path = f"{model_dir}/{TICKER}_best.h5"
    es = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1)
    mc = ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, verbose=1)

    # train
    history = model.fit(X_train_s, y_train_s,
                        validation_data=(X_test_s, y_test_s),
                        epochs=80, batch_size=32,
                        callbacks=[es, mc], verbose=2)

    # predict (ç”¨æ•´å€‹æ¸¬è©¦é›†æœ€å¾Œä¸€å€‹ window åšç¤ºç¯„é æ¸¬ï¼Œæˆ–ä½ å¯ä»¥åš rolling prediction)
    pred_s = model.predict(X_test_s)
    pred = scaler_y.inverse_transform(pred_s)  # shape (n_test_samples, PRED_STEPS)

    # è©•ä¼°ï¼šå°æ¯å€‹é æ¸¬ horizon è¨ˆç®— MAE / RMSEï¼ˆä¹Ÿå¯èšåˆï¼‰
    maes = []
    rmses = []
    for step in range(PRED_STEPS):
        y_true = y_test[:, step]
        y_pred = pred[:, step]
        mae = mean_absolute_error(y_true, y_pred)
        rmse = math.sqrt(mean_squared_error(y_true, y_pred))
        maes.append(mae); rmses.append(rmse)
    print("MAE per step:", np.round(maes, 4))
    print("RMSE per step:", np.round(rmses, 4))
    print("Avg MAE:", np.round(np.mean(maes),4))

    # å°‡æœ€å¾Œä¸€çµ„ X_test çš„æœ€å¾Œä¸€å€‹ window è¦–ç‚ºã€Œä»Šå¤©çš„å·²çŸ¥åºåˆ—ã€
    last_known_index = -1
    last_known_window = X_test[last_known_index]  # shape (LOOKBACK, nfeatures)
    last_known_closes = list(last_known_window[:, 0])  # æœ€å¾ŒçŸ¥é“çš„ LOOKBACK å€‹ close

    pred_of_last = pred[last_known_index]  # length PRED_STEPS
    results = compute_pred_ma_from_pred_closes(last_known_closes, pred_of_last)

    # build df_future_preds using å•†æ¥­æ—¥ï¼ˆäº¤æ˜“æ—¥ï¼‰åºåˆ—
    today = pd.Timestamp(datetime.now().date())
    # ä¸‹ä¸€å€‹äº¤æ˜“æ—¥é–‹å§‹ï¼ˆBDay(1)ä»£è¡¨ä¸‹ä¸€å€‹å·¥ä½œæ—¥ï¼‰
    first_bday = (today + BDay(1)).date()
    business_days = pd.bdate_range(start=first_bday, periods=PRED_STEPS).to_pydatetime()
    future_dates = [pd.Timestamp(d).normalize() for d in business_days]

    df_future = pd.DataFrame({
        "date": future_dates,
        "Pred_Close": [r[0] for r in results],
        "Pred_MA5": [r[1] for r in results],
        "Pred_MA10": [r[2] for r in results]
    })

    # å„²å­˜åœ–ç‰‡ï¼ˆå‘¼å«ä¿®æ­£å¾Œ plot_allï¼‰
    results_dir = "results"
    os.makedirs(results_dir, exist_ok=True)
    today_str = datetime.now().strftime("%Y-%m-%d")
    plot_path = f"{results_dir}/{today_str}_future_pred.png"
    plot_all(df, df_future, hist_days=60)

    # å°å‡ºæœªä¾†é æ¸¬è¡¨
    print(df_future)

    # é¸æ“‡æ€§ï¼šæŠŠé æ¸¬å¯«å› Firestoreï¼ˆè¦–éœ€æ±‚ï¼‰
    if db is not None:
        for i, row in df_future.iterrows():
            date_str = row['date'].strftime("%Y-%m-%d")
            data = {
                "Pred_Close": float(row['Pred_Close']),
                "Pred_MA5": float(row['Pred_MA5']),
                "Pred_MA10": float(row['Pred_MA10'])
            }
            db.collection("NEW_stock_data_liteon_preds").document(date_str).set({"2301.TW": data})
        print("ğŸ”¥ é æ¸¬å¯«å…¥ Firestore å®Œæˆ")

# -*- coding: utf-8 -*-
"""
æ•´åˆç‰ˆï¼šå…‰å¯¶ç§‘ LSTM è‚¡åƒ¹é æ¸¬ + é æ¸¬ 5/10 æ—¥ç·š
ğŸ”¥ åŠŸèƒ½ï¼š
  - æŠ“å–è‚¡åƒ¹
  - è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
  - å¯«å…¥ Firestore
  - è¨“ç·´ LSTM
  - é æ¸¬æœªä¾† MA5 èˆ‡ MA10
  - ç•«åœ–é¡¯ç¤ºï¼ˆæ¯æ—¥åˆ»åº¦ï¼‹å¾ä»Šå¤©é–‹å§‹ç•«ï¼‰
"""

import os, json
import firebase_admin
from firebase_admin import credentials, firestore
import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout


# ============================ ğŸ” Firebase åˆå§‹åŒ– ============================
key_dict = json.loads(os.environ["FIREBASE"])
cred = credentials.Certificate(key_dict)

try:
    firebase_admin.get_app()
except:
    firebase_admin.initialize_app(cred)

db = firestore.client()


# ============================ ğŸ“Œ æŠ“è‚¡ç¥¨ + è¨ˆç®—æŒ‡æ¨™ ============================
def fetch_and_calculate():
    ticker_symbol = "2301.TW"
    stock = yf.Ticker(ticker_symbol)
    df = stock.history(period="6mo")

    # æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
    df['SMA_5'] = df['Close'].rolling(window=5).mean().round(5)
    df['SMA_10'] = df['Close'].rolling(window=10).mean().round(5)

    delta = df['Close'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    df['RSI'] = (100 - (100 / (1 + (gain.rolling(20).mean() / loss.rolling(20).mean())))).round(5)

    df['Lowest_14'] = df['Low'].rolling(window=14).min()
    df['Highest_14'] = df['High'].rolling(window=14).max()
    df['K'] = (100 * (df['Close'] - df['Lowest_14']) / (df['Highest_14'] - df['Lowest_14'])).round(5)
    df['D'] = df['K'].rolling(window=3).mean().round(5)

    df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = (df['EMA_12'] - df['EMA_26']).round(5)

    # è¨ˆç®—æœªä¾† MA5ã€MA10 ä½œç‚º LSTM é æ¸¬ç›®æ¨™
    df['Fut_MA5'] = df['Close'].rolling(5).mean().shift(-4)
    df['Fut_MA10'] = df['Close'].rolling(10).mean().shift(-9)

    return df.dropna()


# ============================ ğŸ’¾ å¯«å…¥ Firestore ============================
def save_to_firestore(df):
    selected = ['Close', 'MACD', 'RSI', 'K', 'D', 'Volume']
    collection = "NEW_stock_data_liteon"

    batch = db.batch()
    count = 0

    for idx, row in df.iterrows():
        date_str = idx.strftime("%Y-%m-%d")
        data = {col: float(row[col]) for col in selected if not pd.isna(row[col])}
        doc_ref = db.collection(collection).document(date_str)
        batch.set(doc_ref, {"2301.TW": data})
        count += 1

        if count >= 300:
            batch.commit()
            batch = db.batch()

    batch.commit()
    print("ğŸ”¥ Firestore å¯«å…¥å®Œæˆ")


# ============================ ğŸ¤– å»º LSTM æ¨¡å‹ ============================
def train_lstm(df):
    features = ['Close', 'Volume', 'MACD', 'RSI', 'K', 'D']
    targets = ['Fut_MA5', 'Fut_MA10']

    scaler_x = MinMaxScaler()
    scaler_y = MinMaxScaler()

    X_scaled = scaler_x.fit_transform(df[features])
    y_scaled = scaler_y.fit_transform(df[targets])

    window = 30
    X, y = [], []

    for i in range(window, len(df)):
        X.append(X_scaled[i-window:i])
        y.append(y_scaled[i])

    X, y = np.array(X), np.array(y)

    model = Sequential([
        LSTM(50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),
        Dropout(0.2),
        LSTM(50),
        Dropout(0.2),
        Dense(2)
    ])

    model.compile(optimizer='adam', loss='mse')
    model.fit(X, y, epochs=30, batch_size=32, verbose=1)

    print("ğŸ‰ LSTM è¨“ç·´å®Œæˆ")
    return model, scaler_x, scaler_y, X_scaled


# ============================ ğŸ”® é æ¸¬æœªä¾† MA5 / MA10 ============================
def predict_future_ma(model, scaler_x, scaler_y, X_scaled, df):
    last_30 = X_scaled[-30:]
    future = []

    for _ in range(10):
        pred = model.predict(last_30.reshape(1, 30, X_scaled.shape[1]), verbose=0)
        future.append(pred[0])

        # ç”¨é æ¸¬å€¼æ›´æ–°åºåˆ—
        new_row = np.zeros((1, X_scaled.shape[1]))
        new_row[0, 0] = pred[0][0]   # ç”¨æœªä¾† MA5 è¿‘ä¼¼ Close
        last_30 = np.append(last_30[1:], new_row, axis=0)

    future_array = np.array(future)
    future_ma = scaler_y.inverse_transform(future_array)

    last_date = pd.to_datetime(df.index[-1])
    dates = [last_date + timedelta(days=i) for i in range(1, 11)]

    df_future = pd.DataFrame({
        "date": dates,
        "Pred_MA5": future_ma[:, 0],
        "Pred_MA10": future_ma[:, 1]
    })

    return df_future


# ============================ ğŸ“ˆ ç•«åœ–ï¼ˆæ¯æ—¥åˆ»åº¦ + å¾ä»Šå¤©é–‹å§‹ï¼‰ ============================
# -*- coding: utf-8 -*-
"""
æ•´åˆç‰ˆï¼šå…‰å¯¶ç§‘ LSTM è‚¡åƒ¹é æ¸¬ + é æ¸¬ 5/10 æ—¥ç·š
ğŸ”¥ åŠŸèƒ½ï¼š
  - æŠ“å–è‚¡åƒ¹
  - è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
  - å¯«å…¥ Firestore
  - è¨“ç·´ LSTM
  - é æ¸¬æœªä¾† MA5 èˆ‡ MA10
  - ç•«åœ–é¡¯ç¤ºï¼ˆæ¯æ—¥åˆ»åº¦ï¼‹å¾ä»Šå¤©é–‹å§‹ç•«ï¼‰
"""

import os, json
import firebase_admin
from firebase_admin import credentials, firestore
import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout


# ============================ ğŸ” Firebase åˆå§‹åŒ– ============================
key_dict = json.loads(os.environ["FIREBASE"])
cred = credentials.Certificate(key_dict)

try:
    firebase_admin.get_app()
except:
    firebase_admin.initialize_app(cred)

db = firestore.client()


# ============================ ğŸ“Œ æŠ“è‚¡ç¥¨ + è¨ˆç®—æŒ‡æ¨™ ============================
def fetch_and_calculate():
    ticker_symbol = "2301.TW"
    stock = yf.Ticker(ticker_symbol)
    df = stock.history(period="6mo")

    # æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
    df['SMA_5'] = df['Close'].rolling(window=5).mean().round(5)
    df['SMA_10'] = df['Close'].rolling(window=10).mean().round(5)

    delta = df['Close'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    df['RSI'] = (100 - (100 / (1 + (gain.rolling(20).mean() / loss.rolling(20).mean())))).round(5)

    df['Lowest_14'] = df['Low'].rolling(window=14).min()
    df['Highest_14'] = df['High'].rolling(window=14).max()
    df['K'] = (100 * (df['Close'] - df['Lowest_14']) / (df['Highest_14'] - df['Lowest_14'])).round(5)
    df['D'] = df['K'].rolling(window=3).mean().round(5)

    df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = (df['EMA_12'] - df['EMA_26']).round(5)

    # è¨ˆç®—æœªä¾† MA5ã€MA10 ä½œç‚º LSTM é æ¸¬ç›®æ¨™
    df['Fut_MA5'] = df['Close'].rolling(5).mean().shift(-4)
    df['Fut_MA10'] = df['Close'].rolling(10).mean().shift(-9)

    return df.dropna()


# ============================ ğŸ’¾ å¯«å…¥ Firestore ============================
def save_to_firestore(df):
    selected = ['Close', 'MACD', 'RSI', 'K', 'D', 'Volume']
    collection = "NEW_stock_data_liteon"

    batch = db.batch()
    count = 0

    for idx, row in df.iterrows():
        date_str = idx.strftime("%Y-%m-%d")
        data = {col: float(row[col]) for col in selected if not pd.isna(row[col])}
        doc_ref = db.collection(collection).document(date_str)
        batch.set(doc_ref, {"2301.TW": data})
        count += 1

        if count >= 300:
            batch.commit()
            batch = db.batch()

    batch.commit()
    print("ğŸ”¥ Firestore å¯«å…¥å®Œæˆ")


# ============================ ğŸ¤– å»º LSTM æ¨¡å‹ ============================
def train_lstm(df):
    features = ['Close', 'Volume', 'MACD', 'RSI', 'K', 'D']
    targets = ['Fut_MA5', 'Fut_MA10']

    scaler_x = MinMaxScaler()
    scaler_y = MinMaxScaler()

    X_scaled = scaler_x.fit_transform(df[features])
    y_scaled = scaler_y.fit_transform(df[targets])

    window = 30
    X, y = [], []

    for i in range(window, len(df)):
        X.append(X_scaled[i-window:i])
        y.append(y_scaled[i])

    X, y = np.array(X), np.array(y)

    model = Sequential([
        LSTM(50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),
        Dropout(0.2),
        LSTM(50),
        Dropout(0.2),
        Dense(2)
    ])

    model.compile(optimizer='adam', loss='mse')
    model.fit(X, y, epochs=30, batch_size=32, verbose=1)

    print("ğŸ‰ LSTM è¨“ç·´å®Œæˆ")
    return model, scaler_x, scaler_y, X_scaled


# ============================ ğŸ”® é æ¸¬æœªä¾† MA5 / MA10 ============================
def predict_future_ma(model, scaler_x, scaler_y, X_scaled, df):
    last_30 = X_scaled[-30:]
    future = []

    for _ in range(10):
        pred = model.predict(last_30.reshape(1, 30, X_scaled.shape[1]), verbose=0)
        future.append(pred[0])

        # ç”¨é æ¸¬å€¼æ›´æ–°åºåˆ—
        new_row = np.zeros((1, X_scaled.shape[1]))
        new_row[0, 0] = pred[0][0]   # ç”¨æœªä¾† MA5 è¿‘ä¼¼ Close
        last_30 = np.append(last_30[1:], new_row, axis=0)

    future_array = np.array(future)
    future_ma = scaler_y.inverse_transform(future_array)

    last_date = pd.to_datetime(df.index[-1])
    dates = [last_date + timedelta(days=i) for i in range(1, 11)]

    df_future = pd.DataFrame({
        "date": dates,
        "Pred_MA5": future_ma[:, 0],
        "Pred_MA10": future_ma[:, 1]
    })

    return df_future


# ============================ ğŸ“ˆ ç•«åœ–ï¼ˆæ¯æ—¥åˆ»åº¦ + å¾ä»Šå¤©é–‹å§‹ï¼‰ ============================
def plot_all(df_real, df_future):

    df_real['date'] = pd.to_datetime(df_real.index)
    df_future['date'] = pd.to_datetime(df_future['date'])

    # åªé¡¯ç¤ºã€Œä»Šå¤©ä¹‹å¾Œã€çš„è³‡æ–™
    today = datetime.now().date()
    df_real = df_real[df_real['date'].dt.date >= today]

    # åˆä½µ
    df_all = pd.concat([
        df_real[['date','Close','SMA_5','SMA_10']], 
        df_future.set_index('date')
    ], axis=0)

    plt.figure(figsize=(12, 6))

    # æ­·å²è³‡æ–™
    if not df_real.empty:
        plt.plot(df_real['date'], df_real['Close'], label="Close", color="blue")
        plt.plot(df_real['date'], df_real['SMA_5'], label="SMA5", color="green")
        plt.plot(df_real['date'], df_real['SMA_10'], label="SMA10", color="orange")

    # é æ¸¬ MA5 / MA10
    plt.plot(df_future['date'], df_future['Pred_MA5'], '--', label="Pred MA5", color="lime")
    plt.plot(df_future['date'], df_future['Pred_MA10'], '--', label="Pred MA10", color="red")

    # === æ¯æ—¥åˆ»åº¦ ===
    ax = plt.gca()
    ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))

    plt.gcf().autofmt_xdate(rotation=45)

    plt.title("2301.TW â€” é æ¸¬ SMA5 / SMA10ï¼ˆæ¯æ—¥åˆ»åº¦ï¼Œå¾ä»Šå¤©é–‹å§‹ï¼‰")
    plt.xlabel("Date")
    plt.ylabel("Price")
    plt.legend()

    results_dir = "results"
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)
    file_path = f"{results_dir}/{today}.png"
    plt.savefig(file_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"ğŸ“Œ åœ–ç‰‡å·²å„²å­˜ï¼š{file_path}")


# ============================ â–¶ï¸ ä¸»æµç¨‹ ============================
if __name__ == "__main__":
    df = fetch_and_calculate()
    save_to_firestore(df)

    model, scaler_x, scaler_y, X_scaled = train_lstm(df)

    df_future = predict_future_ma(model, scaler_x, scaler_y, X_scaled, df)
    plot_all(df, df_future)


# ============================ â–¶ï¸ ä¸»æµç¨‹ ============================
if __name__ == "__main__":
    df = fetch_and_calculate()
    save_to_firestore(df)

    model, scaler_x, scaler_y, X_scaled = train_lstm(df)

    df_future = predict_future_ma(model, scaler_x, scaler_y, X_scaled, df)
    plot_all(df, df_future)
